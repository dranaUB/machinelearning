{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e91f8582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb9a05ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numexpr in c:\\users\\devendra rana\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\devendra rana\\anaconda3\\lib\\site-packages (from numexpr) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user --upgrade numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c5eb4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bottleneck in c:\\users\\devendra rana\\anaconda3\\lib\\site-packages (1.3.8)\n",
      "Requirement already satisfied: numpy in c:\\users\\devendra rana\\anaconda3\\lib\\site-packages (from bottleneck) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user --upgrade bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f14439a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                               text  label\n",
      "0           0      i just feel really helpless and heavy hearted      4\n",
      "1           1  ive enjoyed being able to slouch about relax a...      0\n",
      "2           2  i gave up my internship with the dmrg and am f...      4\n",
      "3           3                         i dont know i feel so lost      0\n",
      "4           4  i am a kindergarten teacher and i am thoroughl...      4\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('text.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e129e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name=['id','text','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc4a8830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                               text  label\n",
      "0   0      i just feel really helpless and heavy hearted      4\n",
      "1   1  ive enjoyed being able to slouch about relax a...      0\n",
      "2   2  i gave up my internship with the dmrg and am f...      4\n",
      "3   3                         i dont know i feel so lost      0\n",
      "4   4  i am a kindergarten teacher and i am thoroughl...      4\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('text.csv', names=col_name,header=0)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af2802b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World This is a test \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_unwanted_characters(text):\n",
    "    # Remove any character that is not a letter or basic punctuation\n",
    "    return re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "# Example usage\n",
    "text = \"Hello, World! This is a test: 1234.\"\n",
    "cleaned_text = remove_unwanted_characters(text)\n",
    "print(cleaned_text)  # Output: Hello World This is a test \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95709085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "def convert_to_lowercase(text):\n",
    "    # Convert text to lowercase\n",
    "    return text.lower()\n",
    "\n",
    "text=\"HELLO WORLD\"\n",
    "print(convert_to_lowercase(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a33cd8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'world']\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "     return text.split()\n",
    "text=\"hello world\"\n",
    "\n",
    "print(tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "41910705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1d7b8d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample', 'text']\n"
     ]
    }
   ],
   "source": [
    "def remove_stop_words(tokens):\n",
    "    return [token for token in tokens if token not in stopwords.words('english')]\n",
    "\n",
    "tokens = ['this', 'is', 'a', 'sample', 'text']\n",
    "cleaned_tokens = remove_stop_words(tokens)\n",
    "print(cleaned_tokens)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4c7d918b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "print(stemmer.stem('running'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dbbfd209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'run', 'runner']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def stem_and_lem_words(tokens):\n",
    "    return [lemmatizer.lemmatize(stemmer.stem(token)) for token in tokens ]\n",
    "\n",
    "tokens = ['running','runs','runner']\n",
    "\n",
    "print(stem_words(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d6485f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feel', 'realli', 'helpless', 'heavi', 'heart']\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    text1=re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text2=text1.lower()\n",
    "    \n",
    "    tokens=text2.split()\n",
    "    tokens1=[token for token in tokens if token not in stopwords.words('english')]\n",
    "    tokens2=[lemmatizer.lemmatize(stemmer.stem(token)) for token in tokens1 ]\n",
    "    return tokens2   \n",
    "\n",
    "print(clean_text('i just feel really helpless and heavy hearted '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "94a3990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text']=df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b149a785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                               text  label  \\\n",
      "0   0      i just feel really helpless and heavy hearted      4   \n",
      "1   1  ive enjoyed being able to slouch about relax a...      0   \n",
      "2   2  i gave up my internship with the dmrg and am f...      4   \n",
      "3   3                         i dont know i feel so lost      0   \n",
      "4   4  i am a kindergarten teacher and i am thoroughl...      4   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0             [feel, realli, helpless, heavi, heart]  \n",
      "1  [ive, enjoy, abl, slouch, relax, unwind, frank...  \n",
      "2         [gave, internship, dmrg, feel, distraught]  \n",
      "3                           [dont, know, feel, lost]  \n",
      "4  [kindergarten, teacher, thoroughli, weari, job...  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649c28c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
